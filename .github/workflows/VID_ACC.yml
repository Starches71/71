
name: Daily Deduplicate YouTube Vids

on:
  schedule:
    - cron: "0 0 * * *"  # runs daily at midnight UTC
  workflow_dispatch:     # allows manual triggering too

jobs:
  deduplicate:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repo
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Remove duplicates and save to txt
      run: |
        def process_file(input_file, output_file):
            seen_ids = set()
            blocks = []
            with open(input_file, 'r', encoding='utf-8') as f:
                content = f.read().strip()

            video_blocks = content.split('\n\n')
            for block in video_blocks:
                lines = block.strip().splitlines()
                for line in lines:
                    if 'youtube.com/watch?v=' in line:
                        vid_id = line.split('watch?v=')[1].split('&')[0].strip()
                        if vid_id not in seen_ids:
                            seen_ids.add(vid_id)
                            blocks.append(block.strip())
                        break

            with open(output_file, 'w', encoding='utf-8') as f:
                f.write('\n\n'.join(blocks) + '\n')

        process_file("VID_LONG_MERGED.txt", "VID_LONG.txt")
        process_file("VID_SHORT_MERGED.txt", "VID_SHORT.txt")

    - name: Commit and push results
      run: |
        git config user.name github-actions
        git config user.email github-actions@github.com
        git add VID_LONG.txt VID_SHORT.txt
        git commit -m "Daily deduplication of YouTube videos"
        git push
